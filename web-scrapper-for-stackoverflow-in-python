''''
Project Name: Python Scrapper 
Description: Python web scrapper application to scrape jobs from stackoveflow. This application will scrape job details from
stackoveflow and save on the csv file.
Author: Madhav Dhungana
Version: 0.1
License: GPL(v1) or v(2)



'''



import requests
from bs4 import BeautifulSoup
import pandas as pd




def page(extract):
    headers = {'User-Agents':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36 OPR/178.0.4093.147'}
    url = f'https://stackoverflow.com/jobs?pg={extract}'
    response = requests.get(url, headers)
    pagecontent = response.text
    if response.status_code != 200:
       raise Exception('Failed to establish connection')
    doc = BeautifulSoup(pagecontent, 'html.parser')
    return doc




def job_title(doc):
    job_title_tags = doc.find_all('h2', {'class': 'mb4 fc-black-800 fs-body3'})
    topic_title_list = []
    for tags in job_title_tags:
        topic_title_list.append(tags.text.strip())
    return topic_title_list


def job_location(doc):
    location = doc.find_all('span', {'class': 'fc-black-500'})
    job_location = []

    for tags in location:
        job_location.append(tags.text.strip())
    return job_location


def company_name(doc):
    name = []
    company = [span for span in (h3.find('span') for h3 in doc.findAll('h3', {'class': 'fc-black-700 fs-body1 mb4'})) if
               span]

    for tags in company:
        name.append(tags.text.strip())
    return name


def required_skills(doc):
    skills = []
    skills_tag = doc.find_all('div', {'class': 'd-inline-flex gs4 fw-wrap'})
    for tags in skills_tag:
        skills.append(tags.text.strip())
    return skills


def job_link(doc):
    joblink = []
    jobbase_url = 'https://stackoverflow.com'
    link_url = doc.find_all('a', {'class': 's-link stretched-link'})
    for tags in link_url:
        joblink.append(jobbase_url + tags['href'])
    return joblink




for test in range(0, 15):
    print(f'Getting page {test} ')
    doc = page(1)
    topics = job_title(doc)
    location = job_location(doc)
    company = company_name(doc)
    skills = required_skills(doc)
    url = job_link(doc)

joblist_dict = {
    'Job Title': topics,
    'Company': company,
    'Location': location,
    'Skills': skills,
    'Job Link': url,
}

alljoblist = []
alljoblist.append(joblist_dict)

job_df = pd.DataFrame(alljoblist)
job_df.to_csv('joblist.csv', encoding='utf-8')

